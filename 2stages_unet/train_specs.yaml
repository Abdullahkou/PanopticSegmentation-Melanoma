# Training specs

'model_architecture': 'unet++ encoder tiefe = 4'
'encoder': 'densenet121'
'optimizer': 'Adam'
'batch_size': 16
'N_epochs': 75
'learning_rate':  0.0001
'weight_decay': 0.005
'scheduler' : 'cosine'
'color_augment': 'Default'
'fine_tuning': ''
'seed': 15
'magnitude': 3
'alpha' : 0.75
'momentum' : 0.9
'unfreeze_from_epoch': 6
'save_model_step': 25
'num_workers': 4
'plot_cm_step': 5
'lossf': "focal_loss [0.1, 1.0, 2.0, 3.0]"
'extra_channels': "foregeround channel added durch extra model"
'num data': "with new data split. ALL (mit aug data with class 2, 3 only)"
"free text": "Attention eingebaut und encoder ist tiefer (4)"