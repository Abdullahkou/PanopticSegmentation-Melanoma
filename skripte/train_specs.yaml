# Training specs

'model_architecture': 'unet++ encoder tiefe = 3 + attenion'
'encoder': 'densenet121'
'optimizer': 'Adam'
'batch_size': 16
'N_epochs': 75
'learning_rate':  0.0001
'weight_decay': 0.005
'scheduler' : 'cosine'
'color_augment': 'Default'
'fine_tuning': ''
'seed': 15
'magnitude': 3
'alpha' : 0.75
'momentum' : 0.9
'unfreeze_from_epoch': 6
'save_model_step': 25
'num_workers': 4
'plot_cm_step': 5
'lossf': "focal_loss [0.1, 1.0, 2.0, 3.0]"
'extra_channels': "gray channel"
'num data': "with new data split. ALL"
"free text": "das neue loss function"