{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "\n",
    "avail_pretrained_models = timm.list_models(\"vit*\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm  # Importieren Sie die timm-Bibliothek f√ºr Vision Transformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ViTSegmentation(nn.Module):\n",
    "    def __init__(self, num_classes=8, pretrained=True):\n",
    "        super(ViTSegmentation, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.vit_model = timm.create_model(\n",
    "            \"vit_base_patch8_224\", pretrained=pretrained)\n",
    "\n",
    "        self.vit_model.head = nn.Conv2d(\n",
    "            in_channels=3, out_channels=num_classes, kernel_size=1, stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTSegmentation(num_classes=8, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lade die CSV-Datei in ein Pandas DataFrame\n",
    "df = pd.read_csv(\n",
    "    r\"\\\\nas-serveurs.tribvn.local\\oceanus\\AID\\AID2\\IGR_Batch_1\\AID-2-corrections-batch-1\\annot_JYS_1703\\wsi_annotations\\wsi_annotations_metadata.csv\"\n",
    ")\n",
    "\n",
    "# Gib die eindeutigen Werte in der Spalte \"slide_name\" aus\n",
    "unique_slide_names_df2 = set(df[\"slide_name\"])\n",
    "print(len(unique_slide_names_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lade die CSV-Datei in ein Pandas DataFrame\n",
    "df2 = pd.read_csv(\n",
    "    r\"\\\\nas-serveurs.tribvn.local\\oceanus\\AID\\AID2\\IGR_Batch_1\\AID-2-corrections-batch-1\\annot_JYS_1703\\wsi_annotations\\wsi_annotations_metadata_foreground.csv\"\n",
    ")\n",
    "# Gib die eindeutigen Werte in der Spalte \"slide_name\" aus\n",
    "unique_slide_names_df1 = set(df2[\"slide_name\"])\n",
    "print(len(unique_slide_names_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'063 - 2021-05-10 21.02.19', '004 - 2021-05-10 16.54.02', '024 - 2021-05-10 18.27.07', '052 - 2021-05-10 20.17.55', '095 - 2021-05-10 23.19.13', '009 - 2021-05-10 17.25.38', '085 - 2021-05-10 22.41.34', '029 - 2021-05-10 18.43.14', '033 - 2021-05-10 18.59.54', '076 - 2021-05-10 22.02.48', '025 - 2021-05-10 18.31.11', '071 - 2021-05-10 21.31.59', '099 - 2021-05-10 23.50.53', '044 - 2021-05-10 19.42.36', '072 - 2021-05-10 21.34.32', '066 - 2021-05-10 21.12.14', '034 - 2021-05-10 19.03.22', '001 - 2021-05-10 16.41.00', '021 - 2021-05-10 18.18.33', '062 - 2021-05-10 20.59.54', '003 - 2021-05-10 16.49.05', '074 - 2021-05-10 21.46.09', '055 - 2021-05-10 20.30.53', '088 - 2021-05-10 22.50.03', '036 - 2021-05-10 19.12.38', '091 - 2021-05-10 22.56.34', '061 - 2021-05-10 20.57.25', '012 - 2021-05-10 17.40.51', '035 - 2021-05-10 19.07.57', '022 - 2021-05-10 18.22.13', '057 - 2021-05-10 20.37.47', '048 - 2021-05-10 20.03.54', '069 - 2021-05-10 21.27.16', '077 - 2021-05-10 22.11.42', '049 - 2021-05-10 20.08.07', '087 - 2021-05-10 22.47.49', '045 - 2021-05-10 19.46.31', '041 - 2021-05-10 19.32.12', '016 - 2021-05-10 17.52.30', '042 - 2021-05-10 19.36.05', '007 - 2021-05-10 17.10.50', '030 - 2021-05-10 18.48.18', '010 - 2021-05-10 17.32.17', '096 - 2021-05-10 23.28.57', '059 - 2021-05-10 20.42.51', '067 - 2021-05-10 21.16.34', '086 - 2021-05-10 22.43.42', '058 - 2021-05-10 20.40.21', '023 - 2021-05-10 18.24.37', '027 - 2021-05-10 18.37.33', '064 - 2021-05-10 21.05.03', '079 - 2021-05-10 22.19.42', '070 - 2021-05-10 21.28.57', '090 - 2021-05-10 22.54.01', '075 - 2021-05-10 21.56.09', '089 - 2021-05-10 22.52.24', '040 - 2021-05-10 19.28.53', '053 - 2021-05-10 20.23.29', '015 - 2021-05-10 17.49.30', '031 - 2021-05-10 18.51.49', '082 - 2021-05-10 22.29.27', '083 - 2021-05-10 22.32.25', '093 - 2021-05-10 23.09.02', '056 - 2021-05-10 20.33.54', '060 - 2021-05-10 20.51.06', '065 - 2021-05-10 21.07.43', '017 - 2021-05-10 17.57.22', '038 - 2021-05-10 19.19.28', '092 - 2021-05-10 23.00.18', '032 - 2021-05-10 18.57.27', '043 - 2021-05-10 19.39.44', '073 - 2021-05-10 21.36.48', '006 - 2021-05-10 17.04.31', '026 - 2021-05-10 18.33.25', '046 - 2021-05-10 19.50.42', '047 - 2021-05-10 19.59.27', '011 - 2021-05-10 17.36.45', '051 - 2021-05-10 20.15.26', '068 - 2021-05-10 21.21.42', '028 - 2021-05-10 18.39.02', '008 - 2021-05-10 17.20.51', '014 - 2021-05-10 17.45.32', '098 - 2021-05-10 23.42.08', '094 - 2021-05-10 23.16.14', '084 - 2021-05-10 22.38.08', '039 - 2021-05-10 19.23.22', '037 - 2021-05-10 19.17.04', '005 - 2021-05-10 16.59.45', '054 - 2021-05-10 20.28.11', '002 - 2021-05-10 16.45.51', '050 - 2021-05-10 20.10.32', '013 - 2021-05-10 17.43.08', '078 - 2021-05-10 22.16.45', '097 - 2021-05-10 23.31.50'}\n"
     ]
    }
   ],
   "source": [
    "schnittmenge = unique_slide_names_df1.intersection(unique_slide_names_df2)\n",
    "\n",
    "print(schnittmenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "print(len(schnittmenge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def color_image_to_mask(color_image):\n",
    "    color_to_class_map = {\n",
    "        (0, 0, 0): 0,\n",
    "        (255, 0, 0): 1,\n",
    "        (251, 220, 0): 2,\n",
    "        (255, 128, 0): 3,\n",
    "        (0, 0, 255): 4,\n",
    "        (255, 0, 255): 5,\n",
    "        (0, 255, 0): 6,\n",
    "        (0, 255, 255): 7,\n",
    "        (128, 128, 128): 8,\n",
    "    }\n",
    "\n",
    "    color_array = np.array(color_image)\n",
    "    unique_colors_before = np.unique(\n",
    "        color_array.reshape(-1, color_array.shape[2]), axis=0)\n",
    "    print(\"Einzigartige Farben vor der Konvertierung:\", unique_colors_before)\n",
    "    mask = np.zeros(\n",
    "        (color_array.shape[0], color_array.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for color, class_value in color_to_class_map.items():\n",
    "        is_color = np.all(color_array == color, axis=-1)\n",
    "        mask[is_color] = class_value\n",
    "\n",
    "    nique_values_after = np.unique(mask)\n",
    "    print(\"Einzigartige Werte nach der Konvertierung:\", nique_values_after)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# def color_image_to_mask(color_image):\n",
    "#     color_to_class_map = {\n",
    "#         (0, 0, 0): 0,\n",
    "#         (255, 0, 0): 1,\n",
    "#         (251, 220, 0): 2,\n",
    "#         (255, 128, 0): 3,\n",
    "#         (0, 0, 255): 4,\n",
    "#         (255, 0, 255): 5,\n",
    "#         (0, 255, 0): 6,\n",
    "#         (0, 255, 255): 7,\n",
    "#         (128, 128, 128): 8,\n",
    "#     }\n",
    "\n",
    "#     color_array = np.array(color_image)\n",
    "#     unique_colors_before = np.unique(\n",
    "#         color_array.reshape(-1, color_array.shape[2]), axis=0)\n",
    "#     print(\"Einzigartige Farben vor der Konvertierung:\", unique_colors_before)\n",
    "\n",
    "#     mask = np.zeros(\n",
    "#         (color_array.shape[0], color_array.shape[1]), dtype=np.uint8)\n",
    "\n",
    "#     for color, class_value in color_to_class_map.items():\n",
    "#         # Konvertieren Sie das Tupel in ein Array, um sicherzustellen, dass die Vergleiche korrekt funktionieren\n",
    "#         color_array_match = color_array == np.array(color).reshape(1, 1, 3)\n",
    "#         mask[color_array_match.all(axis=-1)] = class_value\n",
    "#     unique_values_after = np.unique(mask)\n",
    "#     print(\"Einzigartige Werte nach der Konvertierung:\", unique_values_after)\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzigartige Farben vor der Konvertierung: [[  0   0   0]\n",
      " [  0   0 255]\n",
      " [128 128 128]\n",
      " [255   0   0]]\n",
      "Einzigartige Werte nach der Konvertierung: [0 1 4 8]\n"
     ]
    }
   ],
   "source": [
    "color_image = Image.open(\n",
    "    r\"C:\\Users\\akoukash\\Work_lab\\AID\\data\\ROIs_correct\\session_1_c\\20h03394-01adkhes\\20h03394-01adkhes_33428_44400_class.png\"\n",
    ")\n",
    "\n",
    "mask = color_image_to_mask(color_image)\n",
    "\n",
    "mask_image = Image.fromarray(mask)\n",
    "mask_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
